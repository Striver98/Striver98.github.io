<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/universe.png">
  <link rel="icon" href="/img/universe.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
    <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Wang Zhixuan">
  <meta name="keywords" content="">
  
    <meta name="description" content="国科大宗成庆《自然语言处理与大模型》课程笔记">
<meta property="og:type" content="article">
<meta property="og:title" content="自然语言处理与大模型">
<meta property="og:url" content="https://striver98.github.io/2025/09/22/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%B8%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B/index.html">
<meta property="og:site_name" content="午夜飞行">
<meta property="og:description" content="国科大宗成庆《自然语言处理与大模型》课程笔记">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922225811606.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922225913353.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922230447337.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922231420245.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922231450944.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922231520937.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922231614351.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922231650936.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922231700363.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922231822741.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922231833343.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922232026891.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922232052942.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922232107864.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922232119821.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922232220177.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922233254710.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922233400620.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922233531470.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250929213652965.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250929214017617.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250929214127633.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250929221431597.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250929220739447.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250929221419151.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250929221645275.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250929221704026.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250929221845305.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250929222910590.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250929223435467.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250929223500613.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250929223723651.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930102651598.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930102737864.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930130107737.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930130119163.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930130129179.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930130150585.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930104852186.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930105121103.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930105154102.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930105207320.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930105310136.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930105820783.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930105900913.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930105958659.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930110045224.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930110518457.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930110812298.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930120935635.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930121010601.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930121020437.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930121749457.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930121815118.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930121838589.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930121911551.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930121941942.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930122123995.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930122223095.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930122236826.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930122824585.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930122835454.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930122950771.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930123013645.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930123045046.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930123058671.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930123110539.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016104442470.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016104755293.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016104848109.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016105147327.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016105730885.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016105810014.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016105841994.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016110039419.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016110605832.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016113615651.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016113750302.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016113808619.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016113843008.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016110940595.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016111045320.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016111131791.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016111916592.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016111955238.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016112054699.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016112206984.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016112229855.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016112652811.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016112803585.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016113017472.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016113151837.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016113437079.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016113503121.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016113242658.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016114722265.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016114759723.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016114857677.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016114928927.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016114959422.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016115132504.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016115219992.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017184112470.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017184231345.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017184335865.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017184419970.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017184522338.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017185502290.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017185537174.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017185603969.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017185842433.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017190244636.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017190332484.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017190936847.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017192711856.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017192851838.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017192939164.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017193015881.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017193057388.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017193153363.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017193318623.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017193348424.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017193410119.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017193454480.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017193523297.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251020180753166.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251020181153264.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251117104749904.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251117104647237.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251117104905023.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251117105308002.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251117105514365.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251117105602252.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251117110316968.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251117110348902.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251117110517284.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251117110609954.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251117111047702.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251117111101594.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251117111720548.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251117111745305.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251117111807877.png">
<meta property="og:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251117112408276.png">
<meta property="article:published_time" content="2025-09-22T14:53:46.000Z">
<meta property="article:modified_time" content="2025-11-24T10:55:52.263Z">
<meta property="article:author" content="Wang Zhixuan">
<meta property="article:tag" content="NLP">
<meta property="article:tag" content="LLM">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922225811606.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>自然语言处理与大模型 - 午夜飞行</title>

  <link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css">



  <link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css">

  <link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css">

  <link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css">



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link rel="stylesheet" href="/css/main.css">


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css">
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css">
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"striver98.github.io","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":["home"]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":"lvc5jMNgiDCshZ3sR3KkiNjR-gzGzoHsz","app_key":"yBvnSteGkTHVkCJDH80pXa1d","server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script src="/js/utils.js"></script>
  <script src="/js/color-schema.js"></script>
  

  

  

  

  

  
    
  



  
<!-- hexo injector head_end start --><style>
body hanla:after {
    content: ' ';
    display: inline;
    font-family: inherit;
    font-size: 0.45em;
}

html code hanla,
html pre hanla,
html kbd hanla,
html samp hanla,
html ruby hanla,
html .tag-list-item hanla {
    display: none;
}

html ol > hanla,
html ul > hanla {
    display: none;
}
</style><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style><link rel="alternate" href="/atom.xml" title="午夜飞行" type="application/atom+xml">
</head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>午夜飞行</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/" target="_self">
                <i class="iconfont icon-link-fill"></i>
                <span>友链</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax="true" style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle">自然语言处理与大模型</span>
          
        </div>

        
          
  <div class="mt-3">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-author" aria-hidden="true"></i>
        Wang Zhixuan
      </span>
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-09-22 22:53" pubdate="">
          2025<hanla></hanla>年<hanla></hanla>9<hanla></hanla>月<hanla></hanla>22<hanla></hanla>日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          8.2k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          69 分钟
        
      </span>
    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> 次
        </span>
        

      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">自然语言处理与大模型</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="第1章-绪论">第<hanla></hanla>1<hanla></hanla>章 绪论</h1>
<h2 id="基本概念">基本概念</h2>
<h3 id="术语理解">术语理解</h3>
<ul>
<li><p><u><strong>自然语言理解</strong></u>是探索人类自身语言能力和语言思维活动的本质，研究模仿人类语言认知过程的自然语言处理方法和实现技术的一门学科。它是人工智能早期研究的领域之一，是一门在语言学、计算机科学、认知科学、信息论和数学等多学科基础上形成的交叉学科。（宗成庆，黄昌宁）</p></li>
<li><p><u><strong>计算语言学</strong></u>是通过建立形式化的计算模型来分析、理解和生成自然语言的学科，是人工智能和语言学的分支学科。计算语言学是典型的交叉学科，其研究常常涉及计算机科学、语言学、数学等多个学科的知识。与内容接近的学科自然语言处理相比较，计算语言学更加侧重基础理论和方法的研究。 （常宝宝）</p></li>
<li><p><u><strong>自然语言处理</strong></u>是研究如何利用计算机技术对语言文本（句子、篇章或话语等）进行处理和加工的一门学科，研究内容包括对词法、句法、语义和语用等信息的识别、分类、提取、转换和生成等各种处理方法和实现技术。（宗成庆，黄昌宁）</p></li>
</ul>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922225811606.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="研究内容传统划分">研究内容（传统划分）</h3>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922225913353.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="问题挑战">问题挑战</h2>
<ol type="1">
<li>语言中大量存在不确定性——<strong>歧义 (ambiguity)</strong>
<ul>
<li>语言表达中大量地使用缩略语和隐喻。</li>
</ul></li>
<li>大量存在未知的语言现象
<ul>
<li>新词 、人名、地名、 术语、网络用语等；</li>
<li>新含义；</li>
<li>新用法和新句型等。</li>
</ul></li>
<li>知识表示和获取的复杂性
<ul>
<li>知识（尤其常识）往往是模糊、隐蔽、密切关联地通过自然语言描述的。</li>
</ul></li>
<li>不同语言之间存在概念差异
<ul>
<li>由于历史、文化、宗教和思维方式等差异导致语义概念不对等。</li>
</ul></li>
<li>关于<hanla></hanla>“理解”<hanla></hanla>的标准
<ul>
<li>如何判断计算机系统的智能？——图灵实验<hanla></hanla>(Turing test)</li>
</ul></li>
<li>人脑是如何学习 、 记忆和理解语言的？
<ul>
<li>语言学、心理学</li>
<li>认知科学、神经科学</li>
<li>计算机科学</li>
<li>统计学、信息论</li>
<li>背景知识、常识等</li>
</ul></li>
</ol>
<h2 id="技术方法">技术方法</h2>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922230447337.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="理性主义">理性主义</h3>
<blockquote>
<p>通过对一些代表性语句或语言现象的研究得到对人的语言能力的认识，归纳语言使用的规律，以此分析、推断测试样本的预期结果 。</p>
</blockquote>
<p><strong>基本思路</strong> ：基于规则的分析方法建立符号处理系统</p>
<ul>
<li>设计规则 ：<span class="math inline"><em>N</em> + <em>N</em> → <em>N</em><em>P</em></span></li>
<li>标注词典 ：#工作， <span class="math inline"><em>N</em>(<em>u</em><em>c</em>)</span>； <span class="math inline"><em>V</em></span>；</li>
<li>推导算法 ：归约、推导、歧义消解方法…</li>
</ul>
<p><strong>知识库 + 推理系统 <span class="math inline">→</span> NLP 系统</strong></p>
<h3 id="经验主义">经验主义</h3>
<blockquote>
<p>利用大规真实语言数据，借助人的帮助（标注数据和筛选特征等），统计发现语言使用的规律及其可能性（概率）大小，以此为依据计算预测测试样本的可能结果。统计单元是离散事件（词、短语、词性等 ）。</p>
</blockquote>
<p><strong>问题求解思路</strong>：基于大规模真实数据 建立统计学习模型</p>
<ul>
<li>收集标注数据：真实性、代表性、标注……</li>
<li>统计建型：模型的复杂性、有效性、参数训练……</li>
</ul>
<p><strong>语言数据收集、标注 + 统计模型 <span class="math inline">→</span> NLP 系统</strong></p>
<h3 id="连接主义">连接主义</h3>
<blockquote>
<p>利用超大规模真实语言数据，统计发现语言使用的规律及其可能性（概率）大小，以此为依据计算预测测试样本的可能结果。统计单元采用连续的实数空间表示（向量），充分利用和精细刻画大范围上下文信息，建立统一的模型框架。</p>
</blockquote>
<p><strong>问题求解思路</strong>：基于大规模真实数据 建立深度学习模型</p>
<ul>
<li>收集标注数据：真实性、代表性、标注……</li>
<li>神经网络建模：模型的复杂性、有效性、参数训练……</li>
</ul>
<p><strong>大数据 + 大模型 + 大算力 <span class="math inline">→</span> NLP 系统</strong></p>
<h3 id="以机器翻译为例">以机器翻译为例</h3>
<ol type="1">
<li>基于规则的方法</li>
</ol>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922231420245.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922231450944.png" srcset="/img/loading.gif" lazyload></p>
<ol start="2" type="1">
<li>统计翻译方法</li>
</ol>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922231520937.png" srcset="/img/loading.gif" lazyload></p>
<p><a target="_blank" rel="noopener" href="https://chat.deepseek.com/share/oi9b8c8vukvbyaoziz">关于该方法的一种简单解释</a></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922231614351.png" srcset="/img/loading.gif" lazyload></p>
<ol start="3" type="1">
<li>基于神经网络的翻译方法</li>
</ol>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922231650936.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922231700363.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="课程内容">课程内容</h2>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922231822741.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922231833343.png" srcset="/img/loading.gif" lazyload></p>
<h1 id="第2章-统计学习基础">第<hanla></hanla>2<hanla></hanla>章 统计学习基础</h1>
<h2 id="概率论略览">概率论略览</h2>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922232026891.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="随机过程stochastic-process">随机过程（stochastic process)</h3>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922232052942.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="随机过程的平稳性stationary">随机过程的平稳性<hanla></hanla>(stationary)</h4>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922232107864.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922232119821.png" srcset="/img/loading.gif" lazyload></p>
<blockquote>
<p>例如今天的人民日报内容与昨天的人民日报内容从统计学的角度来说是一致的。</p>
</blockquote>
<h4 id="随机过程的遍历性ergodic">随机过程的遍历性<hanla></hanla>(ergodic)</h4>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922232220177.png" srcset="/img/loading.gif" lazyload></p>
<p>遍历性的核心思想是：<strong>对于某些随机过程，从<hanla></hanla>“一次长时间的观测”<hanla></hanla>中计算出的统计特性，可以等同于从<hanla></hanla>“大量重复实验的集合”<hanla></hanla>中计算出的统计特性。</strong></p>
<p>我们可以通过一个经典的比喻来理解：</p>
<ul>
<li><strong>集合平均</strong>：想象一下，你想知道全国<hanla></hanla>30<hanla></hanla>岁男性的平均身高。
<ul>
<li><strong>方法<hanla></hanla>A（集合平均）</strong>：在某个特定时间点，你找来了<hanla></hanla>1<hanla></hanla>万名<hanla></hanla>30<hanla></hanla>岁的男性，测量他们的身高然后取平均。这相当于对随机过程（30<hanla></hanla>岁男性的身高）在<strong>所有可能的样本（所有<hanla></hanla>30<hanla></hanla>岁男性）</strong> 上求平均。</li>
<li>这个平均值是<strong>理论上的期望值</strong>。</li>
</ul></li>
<li><strong>时间平均</strong>：现在，换一种方法。
<ul>
<li><strong>方法<hanla></hanla>B（时间平均）</strong>：你选定一个男孩，从他出生开始，每年在他生日那天测量他的身高，一直测到他<hanla></hanla>60<hanla></hanla>岁。然后，你从他<hanla></hanla>30<hanla></hanla>岁那年的测量值开始，取到<hanla></hanla>40<hanla></hanla>岁，这<hanla></hanla>10<hanla></hanla>个数据的平均值作为<hanla></hanla>“30<hanla></hanla>岁男性平均身高”<hanla></hanla>的估计。</li>
<li>这相当于对随机过程（这个男性的身高变化）在<strong>时间轴</strong>上求平均。</li>
</ul></li>
</ul>
<p><strong>那么问题来了：方法<hanla></hanla>B（时间平均）得到的结果，能代表方法<hanla></hanla>A（集合平均）的结果吗？</strong></p>
<p><strong>如果答案是<hanla></hanla>“能”，那么这个过程就具有遍历性。</strong></p>
<h2 id="齐夫定律">齐夫定律</h2>
<p><strong>在自然语言的大规模文本数据上统计，一个单词出现的频率与它在频率表中的名次（序号）成反比 。</strong></p>
<p>例如，在 100 万单词的 Brown 语料库中，the 出现的频率最高，出现了 69971 次，占比大约 7 %，名列第一。 单词 of 出现了 36411 次，占比约为 3.5%， 名列第二。 and 出现了 28852 次，约占 2.9%， 名列第三 。 粗略的规律是：按词频顺序，第 r （r<hanla></hanla>为自然数） 个词汇出现的频率为第 1 个词出现频率的 1/r 倍 。 如英语中的<hanla></hanla>the, of, and 这三个词的词频和名次约为： 6:3:2 。 在<hanla></hanla>Brown 语料库中，前 135 个词在整个语料库中约占一半 。</p>
<p>一般而言，假设词汇 <span class="math inline"><em>w</em></span> 出现的频率为 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="1.244ex" height="2.059ex" role="img" focusable="false" viewBox="0 -705 550 910"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g></g></g></svg></mjx-container> ，在排序列表中处于 <span class="math inline"><em>r</em></span> 号位置上 那么 <span class="math inline"><em>f</em></span> 和 <span class="math inline"><em>r</em></span><hanla></hanla>的乘积趋于一个常数 即 $f r=C <span class="math inline">，</span>C$ 为常数 。 如果横轴表示 <span class="math inline"><em>r</em></span> 的对数值 <span class="math inline"><em>l</em><em>o</em><em>g</em>(<em>r</em>)</span>，纵轴表示 <span class="math inline"><em>f</em></span> 的对数值 <span class="math inline"><em>l</em><em>o</em><em>g</em>(<em>f</em>)</span> ，<span class="math inline"><em>l</em><em>o</em><em>g</em>(<em>r</em>)</span> 与 <span class="math inline"><em>l</em><em>o</em><em>g</em>(<em>f</em>)</span><hanla></hanla>的取值关系近似为一条直线 如下图中的蓝线 。</p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922233254710.png" srcset="/img/loading.gif" lazyload></p>
<p>从统计结果看，少数高频词占了整个语料规模的大部分比例，而大部分词汇属于低频词 。 这种现象通常被称为<strong>长尾效应 (long tail effect)</strong>， 相应的词汇称为<strong>长尾词<hanla></hanla>(long tail word)</strong>。 在自然语言处理中考虑到计算量 、 存储量和运算效率等因素，通常只考虑出现词频高于某个阈值的词，而将低于该阈值的长尾词当作<strong>生词 (unknown word)</strong> 处理 。</p>
<h2 id="信息论基础">信息论基础</h2>
<h3 id="熵-entropy">熵 (entropy)</h3>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922233400620.png" srcset="/img/loading.gif" lazyload></p>
<p>熵表示随机变量 <span class="math inline"><em>X</em></span> 每个具体取值<hanla></hanla>(如信源每发射一个信号)<hanla></hanla>所提供的平均信息量。<strong>熵也可以被视为描述一个随机变量的不确定性的数量。一个随机变量的熵越大，它的不确定性越大。那么，正确估计其值的可能性就越小。</strong>越不确定的随机变量越需要大的信息量用以确定其值。</p>
<h3 id="联合熵joint-entropy">联合熵<hanla></hanla>(joint entropy)</h3>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250922233531470.png" srcset="/img/loading.gif" lazyload></p>
<p><strong>联合熵实际上就是描述一对随机变量平均所需要的信息量。</strong></p>
<h3 id="条件熵conditional-entropy">条件熵<hanla></hanla>(conditional entropy)</h3>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250929213652965.png" srcset="/img/loading.gif" lazyload></p>
<p>连锁规则：<span class="math inline"><em>H</em>(<em>X</em>, <em>Y</em>) = <em>H</em>(<em>X</em>) + <em>H</em>(<em>Y</em>|<em>X</em>)</span></p>
<h3 id="相对熵relative-entropy">相对熵<hanla></hanla>(relative entropy)</h3>
<blockquote>
<p>或称<hanla></hanla>Kullback-Leibler divergence, K-L 距离，或<hanla></hanla><strong>K-L<hanla></hanla>散度</strong></p>
</blockquote>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250929214017617.png" srcset="/img/loading.gif" lazyload></p>
<p><strong>相对熵常被用以衡量两个随机分布的差距。当两个随机分布相同时, 其相对熵为<hanla></hanla>0。两个随机分布的差别增加时, 其相对熵也增加。</strong></p>
<h3 id="交叉熵cross-entropy">交叉熵<hanla></hanla>(cross entropy)</h3>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250929214127633.png" srcset="/img/loading.gif" lazyload></p>
<p><strong>交叉熵衡量的也是两个模型分布之间的差异。</strong></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250929221431597.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250929220739447.png" srcset="/img/loading.gif" lazyload></p>
<blockquote>
<p>由此，我们可以根据模型 <span class="math inline"><em>q</em></span> 和一个含有大量数据的 <span class="math inline"><em>L</em></span> 的样本来计算交叉熵。在设计模型 <span class="math inline"><em>q</em></span> 时，我们的目的是使交叉熵最小，从而使模型最接近真实的概率分布<hanla></hanla><span class="math inline"><em>p</em>(<em>x</em>)</span>。</p>
</blockquote>
<h4 id="相对熵和交叉熵的对比分析">相对熵和交叉熵的对比分析</h4>
<ul>
<li><p><strong>交叉熵<hanla></hanla>= 熵<hanla></hanla>+ 相对熵</strong></p></li>
<li><p>在机器学习中，经常用<hanla></hanla><span class="math inline"><em>p</em>(<em>x</em>)</span><hanla></hanla>表示真实数据的概率分布，由于真实数据的概率分布往往无法获得，所以一般通过大量的训练数据来近似。</p></li>
<li><p>假设我们通过某个模型得到了训练数据的概率分布<hanla></hanla><span class="math inline"><em>q</em>(<em>x</em>)</span>，<strong>由于真实数据的概率分布<hanla></hanla><span class="math inline"><em>p</em>(<em>x</em>)</span><hanla></hanla>往往是不变的，因此最小化交叉熵<hanla></hanla><span class="math inline"><em>H</em>(<em>p</em>, <em>q</em>)</span><hanla></hanla>等效于最小化相对熵<hanla></hanla><span class="math inline"><em>D</em>(<em>p</em>||<em>q</em>)</span>。</strong> 习惯上机器学习算法中通常采用<strong>交叉熵</strong>计算损失函数 。</p></li>
</ul>
<h3 id="困惑度perplexity">困惑度<hanla></hanla>(perplexity)</h3>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250929221419151.png" srcset="/img/loading.gif" lazyload></p>
<blockquote>
<p>语言模型设计的任务就是寻找困惑度最小的模型，使其最接近真实的语言分布。</p>
</blockquote>
<h3 id="互信息mutual-information">互信息<hanla></hanla>(mutual information)</h3>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250929221645275.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250929221704026.png" srcset="/img/loading.gif" lazyload></p>
<p>互信息<hanla></hanla><span class="math inline"><em>I</em>(<em>X</em>; <em>Y</em>)</span><hanla></hanla>是在知道了<hanla></hanla><span class="math inline"><em>Y</em></span><hanla></hanla>的值以后<hanla></hanla><span class="math inline"><em>X</em></span><hanla></hanla>的不确定性的减少量，即<hanla></hanla><span class="math inline"><em>Y</em></span><hanla></hanla>的值透露了 多少关于<hanla></hanla><span class="math inline"><em>X</em></span><hanla></hanla>的信息量。</p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250929221845305.png" srcset="/img/loading.gif" lazyload></p>
<p>由于<hanla></hanla><span class="math inline"><em>H</em>(<em>X</em>|<em>X</em>) = 0</span>，所以， <span class="math display"><em>H</em>(<em>x</em>) = <em>H</em>(<em>x</em>) − <em>H</em>(<em>X</em>|<em>X</em>) = <em>I</em>(<em>X</em>; <em>X</em>)</span> 这就是为什么熵又称为自信息<hanla></hanla>(self information) 。这也意味着两个完全相互依赖的变量之间的互信息并不是一个常量，而是取决于它们的熵。</p>
<p>理论上，互信息值越大，表示两个汉字之间的结合越紧密，越可能成词。反之，断开的可能性越大。当两个汉字<hanla></hanla><span class="math inline"><em>x</em></span><hanla></hanla>和<hanla></hanla><span class="math inline"><em>y</em></span><hanla></hanla>关联度较强时，其互信息值<hanla></hanla><span class="math inline"><em>I</em>(<em>x</em>, <em>y</em>) &gt; 0</span>；<span class="math inline"><em>x</em></span><hanla></hanla>与<hanla></hanla><span class="math inline"><em>y</em></span><hanla></hanla>关系弱时，<span class="math inline"><em>I</em>(<em>x</em>, <em>y</em>) ≈ 0</span>；而当<hanla></hanla><span class="math inline"><em>I</em>(<em>x</em>, <em>y</em>) &lt; 0</span><hanla></hanla>时，<span class="math inline"><em>x</em></span> 与<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="1.109ex" height="1.464ex" role="img" focusable="false" viewBox="0 -442 490 647"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container> 称为<hanla></hanla>“互补分布”。</p>
<h2 id="统计学习概念">统计学习概念</h2>
<h3 id="统计学习方法">统计学习方法</h3>
<ul>
<li>数据驱动</li>
<li>对数据进行预测与分析</li>
<li>以方法为中心构建模型</li>
</ul>
<h3 id="统计学习类型">统计学习类型</h3>
<ul>
<li><strong>监督学习 (supervised learning)</strong>
<ul>
<li>给定有限的、人工标注好的大量数据，假设这些数据是独立同分布产生的训练集， training data)</li>
<li>假设要学习的模型属于某个函数的集合，即假设空间 (hypothesis)</li>
<li>应用某（些）个评价准则 (evaluation criterion)，从假设空间中选取最优的模型使其对已知的训练数据和未知的测试数据 (test data)<hanla></hanla>在给定的评价准则下有最优的预测</li>
</ul></li>
<li>非监督学习 (unsupervised learning)</li>
<li>半监督学习 (semi supervised learning)</li>
<li>强化学习 (reinforcement learning)</li>
</ul>
<h4 id="监督学习">监督学习</h4>
<p>一般步骤： ①获得一个有限的训练数据集合 ②确定包含所有可能的模型的假设空间，即学习模型的集合 ③确定模型选择的准则，即学习的策略 ④通过学习方法选择最优模型 ⑤利用学习到的最优模型对新数据进行预测或分析</p>
<p>问题的形式化：</p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250929222910590.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="模型的类别">模型的类别</h3>
<h4 id="生成式方法-generative-model">生成式方法 (generative model)</h4>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250929223435467.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="区分式判别式方法discriminative-model">区分式<hanla></hanla>/<hanla></hanla>判别式方法<hanla></hanla>(Discriminative Model)</h4>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250929223500613.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="相关概念">相关概念</h3>
<ul>
<li>语料 (corpus)/ 语料库 (corpus base)：语言资源（数据集）</li>
<li>训练集 (training data)：用于模型参数训练</li>
<li>开发集 (development data)：用于模拟测试，优化参数</li>
<li>测试集 (test data)：测试模型或模型实际处理的数据</li>
<li>过拟合 (overfitting)：模型只在训练集上性能优良</li>
<li>欠拟合 (under-fitting) ：模型在训练集上性能远未达到最优</li>
<li>鲁棒性 (robustness)： 测试集的差异对模型性能影响不大</li>
</ul>
<h3 id="常用的统计模型">常用的统计模型</h3>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250929223723651.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="最大熵模型及应用">最大熵模型及应用</h2>
<h3 id="问题提出">问题提出</h3>
<p>任何一种语言中，一词多义（歧义）现象是普遍存在的。如何区分不同上下文中的词汇语义，就是词汇歧义消解问题，或称<strong>词义消歧 (word sense disambiguation, WSD)</strong> 。 词义消歧是自然语言处理中的基本问题之一。</p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930102651598.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="解决思路">解决思路</h3>
<p>每个词表达不同的含意时其上下文（语境）往往不同，也就是说，不同的词义对应不同的上下文，因此，如果能够将多义词的上下文区别开，其词义自然就明确了。 <strong>词义消歧变成一个上下文分类任务。</strong></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930102737864.png" srcset="/img/loading.gif" lazyload></p>
<p>基本的上下文信息：<strong>词、词性、位置。</strong></p>
<h3 id="最大熵分类器">最大熵分类器</h3>
<h4 id="基本原理">基本原理</h4>
<p>在只掌握关于未知分布的部分知识的情况下，符合已知知识的概率分布可能有多个，使熵值最大的概率分布能够最真实地反映事件的分布情况。由于熵定义了随机变量的不确定性，当熵最大时，随机变量最不确定 。 也就是说，<strong>在已知部分知识的前提下，关于未知分布最合理的推断应该是符合已知知识最不确定或最</strong> <strong>大随机的推断 。</strong></p>
<p>最大熵模型的核心思想非常直观且深刻：<strong>在满足已知事实（约束条件）的所有可能模型中，选择那个<hanla></hanla>“最不确定”、最均匀的模型，也就是熵最大的模型。</strong></p>
<blockquote>
<p>我们可以通过一个简单的例子来理解：</p>
<p><strong>问题：</strong> 预测一个骰子每个面朝上的概率。</p>
<ol type="1">
<li><strong>没有任何信息时（零约束）：</strong> 我们只知道这是个六面骰子。那么最公平、最不会引入任何主观偏见的假设就是：每个面朝上的概率都是 1/6。这个分布（均匀分布）就是<strong>熵最大</strong>的分布。任何其他的分配方式（比如认为<hanla></hanla>1<hanla></hanla>点概率更大）都是我们在没有证据的情况下强加的假设。</li>
<li><strong>已知一个信息时（一个约束）：</strong> 现在我们通过观察得知：“点数为<hanla></hanla>1<hanla></hanla>的概率是点数为<hanla></hanla>2<hanla></hanla>的概率的两倍”，即 P(1) = 2P(2)。 那么，在<strong>所有满足 P(1) = 2P(2) 的概率分布</strong>中，我们选择最均匀的那个。计算结果是： P(1) = 2/7, P(2) = 1/7, P(3) = 1/7, P(4) = 1/7, P(5) = 1/7, P(6) = 1/7。 这个分布就是满足该约束下的最大熵分布。我们没有对<hanla></hanla>3、4、5、6<hanla></hanla>点做任何额外的假设，所以让它们保持相等。</li>
</ol>
<p><strong>哲学解读：</strong> 最大熵原理承认我们所知道的（约束条件），但对未知部分不做任何主观假设，保持最大的不确定性。这是一种非常保守和稳健的建模原则。</p>
</blockquote>
<p>让熵最大是对未知分布推断最合理的准则。换句话说，<strong>推断未知分布合理的做法是将已知的先验知识作为约束，让未知分布的熵最大。</strong></p>
<h4 id="模型定义">模型定义</h4>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930130107737.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930130119163.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930130129179.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930130150585.png" srcset="/img/loading.gif" lazyload></p>
<p>经推导，有：</p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930104852186.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="确定特征函数">确定特征函数</h4>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930105121103.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930105154102.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930105207320.png" srcset="/img/loading.gif" lazyload></p>
<p>举例：</p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930105310136.png" srcset="/img/loading.gif" lazyload></p>
<p>如果上下文条件由如下三类信息表示： ⑴特征的类型：词形、词性、词形＋词性，3<hanla></hanla>种情况； ⑵上下文窗口大小：当前词的左右<hanla></hanla>2 个词， 1 种情况； ⑶是否考虑位置：是或否，2 种情况。 上述<hanla></hanla>3<hanla></hanla>种情况组合，可得到如下 n 种特征模板：<span class="math inline"><em>n</em> = 3 × 1 × 2 = 6</span> 考虑到词形、词性、位置等又可以组合出很多种可能，可以构造出若干特征函数，因此需要<strong>对特征进行筛选</strong>。</p>
<p>特征选择一般有三种方法： ①从候选特征集中选择那些在训练数据中出现频次、超过一定阈值的特征 ②利用互信息作为评价尺度从候选特征集中选择满足一定互信息要求的特征 ③利用增量式特征选择方法 (Della Pietra et al )<hanla></hanla>从候选特征集中选择特征。 <strong>(比较复杂)</strong> 选定特征之后确定特征函数<hanla></hanla><span class="math inline"><em>f</em></span>，假设共有 <span class="math inline"><em>k</em>(<em>k</em> &gt; 0)</span> 个特征函数。</p>
<h4 id="获取lambda参数">获取<span class="math inline"><em>λ</em></span>参数</h4>
<p>利用<hanla></hanla><strong>GIS(generalized iterative scaling) 算法</strong>：</p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930105820783.png" srcset="/img/loading.gif" lazyload></p>
<p>GIS<hanla></hanla>算法描述：</p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930105900913.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930105958659.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="整个过程">整个过程</h3>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930110045224.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="条件随机场及应用">条件随机场及应用</h2>
<h3 id="模型提出">模型提出</h3>
<p>在<hanla></hanla>NLP<hanla></hanla>和图像处理等任务中，有一类问题是进行序列标注和结构划分，为了解决这类问题 J.Lafferty 等人于 2001 年提出了条件随机场 (conditional random fields, CRFs) 这一概率化的结构模型 。</p>
<p><strong>基本思想</strong>：给定观察序列 <span class="math inline"><em>X</em></span> ，输出标识序列 <span class="math inline"><em>Y</em></span> ，通过计算<hanla></hanla><span class="math inline"><em>P</em>(<em>Y</em>|<em>X</em>)</span><hanla></hanla>求解最优标注序列 。</p>
<h3 id="模型定义-1">模型定义</h3>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930110518457.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930110812298.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930120935635.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930121010601.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930121020437.png" srcset="/img/loading.gif" lazyload></p>
<p>具体解释如下：</p>
<h4 id="核心思想什么是crf">1. 核心思想：什么是<hanla></hanla>CRF？</h4>
<p>简单来说，CRF<hanla></hanla>是一种<strong>判别式</strong>的<strong>概率图模型</strong>，主要用于对<strong>序列数据</strong>进行标注和分割。</p>
<p>我们可以拆解这三个关键词来理解：</p>
<ol type="1">
<li><strong>判别式模型</strong>：
<ul>
<li>与<strong>生成式模型</strong>（如朴素贝叶斯、隐马尔可夫模型）不同，判别式模型直接学习<strong>条件概率 P(Y|X)</strong>，即给定输入序列 X，输出最可能的标签序列 Y。</li>
<li><strong>打个比方</strong>：生成式模型是学习<hanla></hanla>“每个动物长什么样（P(特征|类别)）”，然后根据样子来分类；判别式模型是直接学习<hanla></hanla>“如何区分猫和狗（P(类别|特征））”。CRF<hanla></hanla>关心的是<strong>给定一句话（观测序列<hanla></hanla>X），最可能的词性标注序列（标签序列<hanla></hanla>Y）是什么</strong>，而不去建模这句话本身产生的概率 P(X)。</li>
</ul></li>
<li><strong>概率图模型</strong>：
<ul>
<li>CRF<hanla></hanla>使用一个<strong>无向图</strong>（通常是线性链）来表示变量之间的依赖关系。</li>
<li>图中的节点代表随机变量（标签 Y 和观测 X），边代表变量之间的依赖关系。</li>
</ul></li>
<li><strong>条件随机场</strong>：
<ul>
<li>“条件”<hanla></hanla>体现在模型是直接对 P(Y|X) 建模。</li>
<li>“随机场”<hanla></hanla>可以理解为一组随机变量，它们在一个图结构中，其联合概率分布可以由图的势函数来定义。</li>
</ul></li>
</ol>
<p><strong>CRF<hanla></hanla>要解决的核心问题是：在序列标注中，当前的标签不仅与当前的输入（观测）有关，还与它</strong>前后<strong>的标签有关。</strong> 例如，在词性标注中，一个动词后面很可能跟一个名词或副词，而不太可能再跟一个动词。CRF<hanla></hanla>的强大之处就在于它能够<strong>综合考虑整个观测序列和标签序列的上下文信息</strong>，来做出全局最优的决策。</p>
<h4 id="数学模型crf如何工作">2. 数学模型：CRF<hanla></hanla>如何工作？</h4>
<p>我们以最常用的<strong>线性链条件随机场</strong> 为例，它非常适合序列问题。</p>
<h5 id="图结构">2.1 图结构</h5>
<p>线性链<hanla></hanla>CRF<hanla></hanla>的图结构如下所示：</p>
<figure class="highlight tp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs tp"><span class="hljs-keyword">Y</span><span class="hljs-number">1</span>----<span class="hljs-keyword">Y</span><span class="hljs-number">2</span>----<span class="hljs-keyword">Y</span><span class="hljs-number">3</span>----...----Yn<br>|     |     |            |<br><span class="hljs-keyword">X</span><span class="hljs-number">1</span>    <span class="hljs-keyword">X</span><span class="hljs-number">2</span>    <span class="hljs-keyword">X</span><span class="hljs-number">3</span>   ...     Xn<br></code></pre></td></tr></tbody></table></figure>
<ul>
<li><code>Y1, Y2, ..., Yn</code> 构成一个线性链，表示标签序列。<code>Yi</code> 与 <code>Yi-1</code> 和 <code>Yi+1</code> 直接相连。</li>
<li><code>X1, X2, ..., Xn</code> 是观测序列。</li>
<li>每个标签 <code>Yi</code> 都依赖于整个观测序列 X（理论上），但在实践中，通常只依赖于当前时刻的观测 <code>Xi</code> 或一个局部窗口。</li>
</ul>
<p>这个结构意味着，标签序列 Y 的联合概率，在给定观测序列 X 的条件下，是由这个图结构所定义的。</p>
<h5 id="特征函数和能量函数">2.2 特征函数和能量函数</h5>
<p>CRF<hanla></hanla>不直接定义概率，而是先定义一个<strong>能量函数</strong>，然后通过指数化和归一化来得到概率。能量越低，序列的可能性越大。</p>
<p>CRF<hanla></hanla>定义在<strong>特征函数</strong> 之上。特征函数是<hanla></hanla>CRF<hanla></hanla>的灵魂，它表达了我们的<hanla></hanla>“直觉”<hanla></hanla>或<hanla></hanla>“规则”，用于衡量观测序列和标签序列的某种匹配程度。特征函数分为两类：</p>
<ol type="1">
<li><strong>状态特征函数</strong>：关联一个<strong>单个</strong>的标签节点 <code>Yi</code> 和观测序列 X。
<ul>
<li>形式：<code>s_l(Yi, X, i)</code></li>
<li><strong>含义</strong>：在位置 i，当标签为 <code>Yi</code>，并且观测序列是 X 时，这个特征有多强。</li>
<li><strong>例子</strong>：在词性标注中，一个特征函数可能是：<code>如果单词 Xi 以<hanla></hanla>‘-ing’<hanla></hanla>结尾，并且标签 Yi 是<hanla></hanla>‘动词<hanla></hanla>(VBG)’</code>，那么返回 1，否则返回 0。</li>
</ul></li>
<li><strong>转移特征函数</strong>：关联<strong>一对相邻</strong>的标签节点 <code>(Yi-1, Yi)</code> 和观测序列 X。
<ul>
<li>形式：<code>t_k(Yi-1, Yi, X, i)</code></li>
<li><strong>含义</strong>：在位置 i，当从上一个标签 <code>Yi-1</code> 转移到当前标签 <code>Yi</code>，并且观测序列是 X 时，这个特征有多强。</li>
<li><strong>例子</strong>：在词性标注中，一个特征函数可能是：<code>如果前一个标签 Yi-1 是<hanla></hanla>‘冠词<hanla></hanla>(DT)’，并且当前标签 Yi 是<hanla></hanla>‘名词<hanla></hanla>(NN)’</code>，那么返回 1，否则返回 0。</li>
</ul></li>
</ol>
<p>每个特征函数 <code>f_m</code>（可以是状态特征 <code>s_l</code> 或转移特征 <code>t_k</code>）都有一个对应的权重 <code>λ_m</code>，这个权重在训练中学得。权重表明了该特征的重要性。正权重意味着我们鼓励这种情况出现，负权重意味着我们抑制这种情况。</p>
<h5 id="条件概率公式">2.3 条件概率公式</h5>
<p>结合所有特征函数和它们的权重，线性链<hanla></hanla>CRF<hanla></hanla>定义的条件概率分布如下：</p>
<p><span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.827ex;" xmlns="http://www.w3.org/2000/svg" width="71.884ex" height="6.785ex" role="img" focusable="false" viewBox="0 -1749.5 31772.8 2999"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="mo" transform="translate(751,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1140,0)"><path data-c="1D44C" d="M66 637Q54 637 49 637T39 638T32 641T30 647T33 664T42 682Q44 683 56 683Q104 680 165 680Q288 680 306 683H316Q322 677 322 674T320 656Q316 643 310 637H298Q242 637 242 624Q242 619 292 477T343 333L346 336Q350 340 358 349T379 373T411 410T454 461Q546 568 561 587T577 618Q577 634 545 637Q528 637 528 647Q528 649 530 661Q533 676 535 679T549 683Q551 683 578 682T657 680Q684 680 713 681T746 682Q763 682 763 673Q763 669 760 657T755 643Q753 637 734 637Q662 632 617 587Q608 578 477 424L348 273L322 169Q295 62 295 57Q295 46 363 46Q379 46 384 45T390 35Q390 33 388 23Q384 6 382 4T366 1Q361 1 324 1T232 2Q170 2 138 2T102 1Q84 1 84 9Q84 14 87 24Q88 27 89 30T90 35T91 39T93 42T96 44T101 45T107 45T116 46T129 46Q168 47 180 50T198 63Q201 68 227 171L252 274L129 623Q128 624 127 625T125 627T122 629T118 631T113 633T105 634T96 635T83 636T66 637Z"></path></g><g data-mml-node="mo" transform="translate(1903,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="mi" transform="translate(2181,0)"><path data-c="1D44B" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"></path></g><g data-mml-node="mo" transform="translate(3033,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(3699.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(4755.6,0)"><g data-mml-node="mn" transform="translate(1146.5,676)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mrow" transform="translate(220,-710)"><g data-mml-node="mi"><path data-c="1D44D" d="M58 8Q58 23 64 35Q64 36 329 334T596 635L586 637Q575 637 512 637H500H476Q442 637 420 635T365 624T311 598T266 548T228 469Q227 466 226 463T224 458T223 453T222 450L221 448Q218 443 202 443Q185 443 182 453L214 561Q228 606 241 651Q249 679 253 681Q256 683 487 683H718Q723 678 723 675Q723 673 717 649Q189 54 188 52L185 49H274Q369 50 377 51Q452 60 500 100T579 247Q587 272 590 277T603 282H607Q628 282 628 271Q547 5 541 2Q538 0 300 0H124Q58 0 58 8Z"></path></g><g data-mml-node="mo" transform="translate(723,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1112,0)"><path data-c="1D44B" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"></path></g><g data-mml-node="mo" transform="translate(1964,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><rect width="2553" height="60" x="120" y="220"></rect></g><g data-mml-node="mi" transform="translate(7548.6,0)"><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z"></path><path data-c="78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z" transform="translate(444,0)"></path><path data-c="70" d="M36 -148H50Q89 -148 97 -134V-126Q97 -119 97 -107T97 -77T98 -38T98 6T98 55T98 106Q98 140 98 177T98 243T98 296T97 335T97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 61 434T98 436Q115 437 135 438T165 441T176 442H179V416L180 390L188 397Q247 441 326 441Q407 441 464 377T522 216Q522 115 457 52T310 -11Q242 -11 190 33L182 40V-45V-101Q182 -128 184 -134T195 -145Q216 -148 244 -148H260V-194H252L228 -193Q205 -192 178 -192T140 -191Q37 -191 28 -194H20V-148H36ZM424 218Q424 292 390 347T305 402Q234 402 182 337V98Q222 26 294 26Q345 26 384 80T424 218Z" transform="translate(972,0)"></path></g><g data-mml-node="mo" transform="translate(9076.6,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mrow" transform="translate(9243.2,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M758 -1237T758 -1240T752 -1249H736Q718 -1249 717 -1248Q711 -1245 672 -1199Q237 -706 237 251T672 1700Q697 1730 716 1749Q718 1750 735 1750H752Q758 1744 758 1741Q758 1737 740 1713T689 1644T619 1537T540 1380T463 1176Q348 802 348 251Q348 -242 441 -599T744 -1218Q758 -1237 758 -1240Z"></path></g><g data-mml-node="munderover" transform="translate(792,0)"><g data-mml-node="mo"><path data-c="2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path></g><g data-mml-node="TeXAtom" transform="translate(148.2,-1087.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(345,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1123,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(509.9,1150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(2402.7,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M758 -1237T758 -1240T752 -1249H736Q718 -1249 717 -1248Q711 -1245 672 -1199Q237 -706 237 251T672 1700Q697 1730 716 1749Q718 1750 735 1750H752Q758 1744 758 1741Q758 1737 740 1713T689 1644T619 1537T540 1380T463 1176Q348 802 348 251Q348 -242 441 -599T744 -1218Q758 -1237 758 -1240Z"></path></g><g data-mml-node="munder" transform="translate(792,0)"><g data-mml-node="mo"><path data-c="2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path></g><g data-mml-node="TeXAtom" transform="translate(537.8,-1107.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g></g></g><g data-mml-node="msub" transform="translate(2402.7,0)"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="mi" transform="translate(616,-150) scale(0.707)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g></g><g data-mml-node="msub" transform="translate(3437.1,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(394,-150) scale(0.707)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g></g><g data-mml-node="mo" transform="translate(4249.5,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(4638.5,0)"><g data-mml-node="mi"><path data-c="1D44C" d="M66 637Q54 637 49 637T39 638T32 641T30 647T33 664T42 682Q44 683 56 683Q104 680 165 680Q288 680 306 683H316Q322 677 322 674T320 656Q316 643 310 637H298Q242 637 242 624Q242 619 292 477T343 333L346 336Q350 340 358 349T379 373T411 410T454 461Q546 568 561 587T577 618Q577 634 545 637Q528 637 528 647Q528 649 530 661Q533 676 535 679T549 683Q551 683 578 682T657 680Q684 680 713 681T746 682Q763 682 763 673Q763 669 760 657T755 643Q753 637 734 637Q662 632 617 587Q608 578 477 424L348 273L322 169Q295 62 295 57Q295 46 363 46Q379 46 384 45T390 35Q390 33 388 23Q384 6 382 4T366 1Q361 1 324 1T232 2Q170 2 138 2T102 1Q84 1 84 9Q84 14 87 24Q88 27 89 30T90 35T91 39T93 42T96 44T101 45T107 45T116 46T129 46Q168 47 180 50T198 63Q201 68 227 171L252 274L129 623Q128 624 127 625T125 627T122 629T118 631T113 633T105 634T96 635T83 636T66 637Z"></path></g><g data-mml-node="TeXAtom" transform="translate(614,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(345,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1123,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(6450.1,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(6894.8,0)"><g data-mml-node="mi"><path data-c="1D44C" d="M66 637Q54 637 49 637T39 638T32 641T30 647T33 664T42 682Q44 683 56 683Q104 680 165 680Q288 680 306 683H316Q322 677 322 674T320 656Q316 643 310 637H298Q242 637 242 624Q242 619 292 477T343 333L346 336Q350 340 358 349T379 373T411 410T454 461Q546 568 561 587T577 618Q577 634 545 637Q528 637 528 647Q528 649 530 661Q533 676 535 679T549 683Q551 683 578 682T657 680Q684 680 713 681T746 682Q763 682 763 673Q763 669 760 657T755 643Q753 637 734 637Q662 632 617 587Q608 578 477 424L348 273L322 169Q295 62 295 57Q295 46 363 46Q379 46 384 45T390 35Q390 33 388 23Q384 6 382 4T366 1Q361 1 324 1T232 2Q170 2 138 2T102 1Q84 1 84 9Q84 14 87 24Q88 27 89 30T90 35T91 39T93 42T96 44T101 45T107 45T116 46T129 46Q168 47 180 50T198 63Q201 68 227 171L252 274L129 623Q128 624 127 625T125 627T122 629T118 631T113 633T105 634T96 635T83 636T66 637Z"></path></g><g data-mml-node="mi" transform="translate(614,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(7802.7,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(8247.4,0)"><path data-c="1D44B" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"></path></g><g data-mml-node="mo" transform="translate(9099.4,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(9544.1,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(9889.1,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(10500.3,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="munder" transform="translate(11500.5,0)"><g data-mml-node="mo"><path data-c="2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path></g><g data-mml-node="TeXAtom" transform="translate(616.6,-1107.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g></g><g data-mml-node="msub" transform="translate(13111.2,0)"><g data-mml-node="mi"><path data-c="1D707" d="M58 -216Q44 -216 34 -208T23 -186Q23 -176 96 116T173 414Q186 442 219 442Q231 441 239 435T249 423T251 413Q251 401 220 279T187 142Q185 131 185 107V99Q185 26 252 26Q261 26 270 27T287 31T302 38T315 45T327 55T338 65T348 77T356 88T365 100L372 110L408 253Q444 395 448 404Q461 431 491 431Q504 431 512 424T523 412T525 402L449 84Q448 79 448 68Q448 43 455 35T476 26Q485 27 496 35Q517 55 537 131Q543 151 547 152Q549 153 557 153H561Q580 153 580 144Q580 138 575 117T555 63T523 13Q510 0 491 -8Q483 -10 467 -10Q446 -10 429 -4T402 11T385 29T376 44T374 51L368 45Q362 39 350 30T324 12T288 -4T246 -11Q199 -11 153 12L129 -85Q108 -167 104 -180T92 -202Q76 -216 58 -216Z"></path></g><g data-mml-node="mi" transform="translate(636,-150) scale(0.707)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g><g data-mml-node="msub" transform="translate(14007.9,0)"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(502,-150) scale(0.707)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g><g data-mml-node="mo" transform="translate(14770.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(15159.6,0)"><g data-mml-node="mi"><path data-c="1D44C" d="M66 637Q54 637 49 637T39 638T32 641T30 647T33 664T42 682Q44 683 56 683Q104 680 165 680Q288 680 306 683H316Q322 677 322 674T320 656Q316 643 310 637H298Q242 637 242 624Q242 619 292 477T343 333L346 336Q350 340 358 349T379 373T411 410T454 461Q546 568 561 587T577 618Q577 634 545 637Q528 637 528 647Q528 649 530 661Q533 676 535 679T549 683Q551 683 578 682T657 680Q684 680 713 681T746 682Q763 682 763 673Q763 669 760 657T755 643Q753 637 734 637Q662 632 617 587Q608 578 477 424L348 273L322 169Q295 62 295 57Q295 46 363 46Q379 46 384 45T390 35Q390 33 388 23Q384 6 382 4T366 1Q361 1 324 1T232 2Q170 2 138 2T102 1Q84 1 84 9Q84 14 87 24Q88 27 89 30T90 35T91 39T93 42T96 44T101 45T107 45T116 46T129 46Q168 47 180 50T198 63Q201 68 227 171L252 274L129 623Q128 624 127 625T125 627T122 629T118 631T113 633T105 634T96 635T83 636T66 637Z"></path></g><g data-mml-node="mi" transform="translate(614,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(16067.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(16512.2,0)"><path data-c="1D44B" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"></path></g><g data-mml-node="mo" transform="translate(17364.2,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(17808.9,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(18153.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(18542.9,0) translate(0 -0.5)"><path data-c="29" d="M33 1741Q33 1750 51 1750H60H65Q73 1750 81 1743T119 1700Q554 1207 554 251Q554 -707 119 -1199Q76 -1250 66 -1250Q65 -1250 62 -1250T56 -1249Q55 -1249 53 -1249T49 -1250Q33 -1250 33 -1239Q33 -1236 50 -1214T98 -1150T163 -1052T238 -910T311 -727Q443 -335 443 251Q443 402 436 532T405 831T339 1142T224 1438T50 1716Q33 1737 33 1741Z"></path></g></g><g data-mml-node="mo" transform="translate(21737.6,0) translate(0 -0.5)"><path data-c="29" d="M33 1741Q33 1750 51 1750H60H65Q73 1750 81 1743T119 1700Q554 1207 554 251Q554 -707 119 -1199Q76 -1250 66 -1250Q65 -1250 62 -1250T56 -1249Q55 -1249 53 -1249T49 -1250Q33 -1250 33 -1239Q33 -1236 50 -1214T98 -1150T163 -1052T238 -910T311 -727Q443 -335 443 251Q443 402 436 532T405 831T339 1142T224 1438T50 1716Q33 1737 33 1741Z"></path></g></g></g></g></svg></mjx-container></span></p>
<ul>
<li><strong>指数内部</strong>：对序列中每一个位置 i，将所有状态特征和转移特征的加权和累加起来。这个和可以看作是整个标签序列 Y 和观测序列 X 的<hanla></hanla>“兼容度得分”。</li>
<li><strong>Z(X)</strong>：<strong>归一化因子</strong>，也称为配分函数。它确保所有可能的标签序列 Y 的概率之和为 1。<code>Z(X) = Σ_{Y} exp( ... )</code>，计算它需要枚举所有可能的 Y，在长序列上计算量很大。</li>
<li><strong>exp(.)</strong>：将得分转化为正数，并通过归一化转化为概率。</li>
</ul>
<h3 id="模型实现">模型实现</h3>
<h4 id="特征选取">特征选取</h4>
<p>与最大熵模型采用的方式相同</p>
<blockquote>
<p>特征选择一般有三种方法： ①从候选特征集中选择那些在训练数据中出现频次、超过一定阈值的特征 ②利用互信息作为评价尺度从候选特征集中选择满足一定互信息要求的特征 ③利用增量式特征选择方法 (Della Pietra et al )<hanla></hanla>从候选特征集中选择特征。 <strong>(比较复杂)</strong> 选定特征之后确定特征函数<hanla></hanla><span class="math inline"><em>f</em></span>，假设共有 <span class="math inline"><em>k</em>(<em>k</em> &gt; 0)</span> 个特征函数。</p>
</blockquote>
<h4 id="参数训练">参数训练</h4>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930121749457.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930121815118.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930121838589.png" srcset="/img/loading.gif" lazyload></p>
<p>算法描述：</p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930121911551.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="解码">解码</h4>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930121941942.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930122123995.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930122223095.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930122236826.png" srcset="/img/loading.gif" lazyload></p>
<p><a target="_blank" rel="noopener" href="https://chat.deepseek.com/share/5k8yg35xi905h227ki">一种解释</a></p>
<h3 id="crfs-应用举例">CRFs 应用举例</h3>
<p>基于字标注的分词方法<hanla></hanla>(Character based tagging)</p>
<p>基本思想：将分词过程看作是字的分类问题，每个字在构造一个特定的词语时都占据着一个确定的构词位置，即词位 。 一般而言，每个字只有 4 个词位 词首 (B) 、 词中 (M) 、词尾 (E) 和单独成词 (S) 。</p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930122824585.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930122835454.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930122950771.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930123013645.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930123045046.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930123058671.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20250930123110539.png" srcset="/img/loading.gif" lazyload></p>
<h1 id="第3章-n元文法模型">第<hanla></hanla>3<hanla></hanla>章 N<hanla></hanla>元文法模型</h1>
<h2 id="模型定义-2">模型定义</h2>
<h3 id="问题提出-1">问题提出</h3>
<p>如何计算一段文字（句子）的概率？</p>
<blockquote>
<p>​ 阳春三月春意盎然，少先队员脸上荡漾着喜悦的笑容，鲜艳的红领巾在他们的胸前迎风飘扬。</p>
</blockquote>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016104442470.png" srcset="/img/loading.gif" lazyload></p>
<p><strong><u>问题</u></strong>：随着历史基元数量的增加，不同的”<hanla></hanla>历史<hanla></hanla>“组合构成的路径数量指数级增长。</p>
<h3 id="问题的解决方法">问题的解决方法</h3>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016104755293.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016104848109.png" srcset="/img/loading.gif" lazyload></p>
<p>这种语句概率计算模型称为<strong>语言模型<hanla></hanla>(language model, LM)</strong>，又称<hanla></hanla><strong>n<hanla></hanla>元文法模型<hanla></hanla>(n-gram model)</strong>。</p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016105147327.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="参数估计">参数估计</h2>
<h3 id="基本思路">基本思路</h3>
<ul>
<li>收集、标注大规模样本，我们称其为训练数据<hanla></hanla>/<hanla></hanla>语料<hanla></hanla>(training data/corpus)</li>
<li>利用<strong>最大似然估计<hanla></hanla>(maximum likelihood evaluation,MLE)</strong><hanla></hanla>方法计算概率</li>
</ul>
<h3 id="实现方法">实现方法</h3>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016105730885.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016105810014.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016105841994.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016110039419.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="数据平滑">数据平滑</h2>
<h3 id="基本思想">基本思想</h3>
<p>​ 调整最大似然估计的概率值，使零概率增值，使非零概率下调，<strong>劫富济贫</strong>，消除零概率，改进模型的整体正确率。</p>
<ul>
<li>目标：测试样本的语言模型<strong>困惑度越小越好</strong>。</li>
<li>约束：<span class="math inline">∑<sub><em>w</em><sub><em>i</em></sub></sub><em>p</em>(<em>w</em><sub><em>i</em></sub>|<em>w</em><sub><em>i</em> − <em>n</em> + 1</sub><sup><em>j</em> − 1</sup>) = 1</span></li>
</ul>
<p>回顾—困惑度：</p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016110605832.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="数据平滑方法">数据平滑方法</h3>
<ol type="1">
<li>加<hanla></hanla>1<hanla></hanla>法<hanla></hanla>(additive)</li>
<li>减值法<hanla></hanla>/<hanla></hanla>折扣法<hanla></hanla>(discounting)</li>
<li>删除插值法<hanla></hanla>(deleted interpolation)</li>
</ol>
<h4 id="加1平滑法">加<hanla></hanla>1<hanla></hanla>平滑法</h4>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016113615651.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016113750302.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016113808619.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016113843008.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="n元文法模型应用">N<hanla></hanla>元文法模型应用</h2>
<h3 id="模型应用1计算语句的概率以便于相关任务中筛选最有可能的语句">模型应用<hanla></hanla>1：计算语句的概率，以便于相关任务中筛选最有可能的语句</h3>
<p>以汉语分词为例</p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016110940595.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="方法描述">方法描述</h4>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016111045320.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="一种改进的实现方法">一种改进的实现方法</h4>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016111131791.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016111916592.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016111955238.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016112054699.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016112206984.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016112229855.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="模型训练">模型训练</h4>
<ol type="1">
<li>在词表和派生词表的基础上，用一个基本的分词工具切分训练语料；专有名词通过一个专门模块标注，实体名词通过相应的规则和有限状态自动机标注，由此产生一个带词类别标记的初始语料；</li>
<li>用带词类别标记的初始语料，采用最大似然估计方法估计语言模型的概率参数公式<hanla></hanla>(7)；</li>
<li>用得到的模型对训练语料重新切分和标注，得到新的训练语料；</li>
<li>重复<hanla></hanla>2、3<hanla></hanla>步，直到系统的性能不再有明显的变化为止。</li>
</ol>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016112652811.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016112803585.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016113017472.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="实验语料">实验语料</h4>
<ol type="1">
<li>词表词： 98,668 条、派生词： 59,285 条；</li>
<li>训练语料： 88MB 新闻文本；</li>
<li>测试集： 247,039 个词次，分别来自描写文、叙述文、说明文、口语等。</li>
</ol>
<h4 id="测试指标">测试指标</h4>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016113151837.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="模型应用2已知前面的词语预测生成后面的语句自动写作">模型应用<hanla></hanla>2：已知前面的词语，预测生成后面的语句（自动写作）</h3>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016113437079.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016113503121.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="n-元文法模型的广泛应用">N-元文法模型的广泛应用</h3>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016113242658.png" srcset="/img/loading.gif" lazyload></p>
<h1 id="第4章-传统nlp技术简介">第<hanla></hanla>4<hanla></hanla>章 传统<hanla></hanla>NLP<hanla></hanla>技术简介</h1>
<ul>
<li>这里所说的<hanla></hanla>“传统 NLP 技术”<hanla></hanla>是指基于神经网络的深度学习方法出现之前的自然语言处理技术，包括理性主义方法和经验主义方法。</li>
<li>传统的 NLP 方法通常需要如下三个步骤：<strong>词语切分与命名实体识别；句法分析；语义分析。</strong>因此，本章简要介绍以下三方面关键技术。</li>
</ul>
<h2 id="词语切分与命名实体识别">词语切分与命名实体识别</h2>
<h3 id="分词要点">分词要点</h3>
<h4 id="切分意义">切分意义</h4>
<ul>
<li>词是语言中能够独立使用的最小的语言单位；</li>
<li>词语切分在传统的 NLP 方法中是句子结构分析、语义分析和篇章分析等后续任务完成的前提和基础；</li>
<li>到目前为止，所有的 NLP 方法，包括深度学习方法，都是以词或子词为统计基元建模实现的；</li>
<li>词语切分具有广泛的应用，如词频统计，词典编纂，文章风格研究，文献处理，文本校对，简繁体转换等 。</li>
</ul>
<h4 id="汉语自动分词中的主要问题">汉语自动分词中的主要问题</h4>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016114722265.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016114759723.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016114857677.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016114928927.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016114959422.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="汉语自动分词的基本原则">汉语自动分词的基本原则</h4>
<ol type="1">
<li><strong>语义上无法由组合成分直接相加而得到的字串应该合并为一个分词单位。</strong>
<ul>
<li><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016115132504.png" srcset="/img/loading.gif" lazyload></li>
</ul></li>
<li><strong>语类无法由组合成分直接得到的字串应该合并为一个分词单位。</strong>
<ul>
<li><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251016115219992.png" srcset="/img/loading.gif" lazyload></li>
</ul></li>
</ol>
<h4 id="汉语自动分词的辅助原则">汉语自动分词的辅助原则</h4>
<blockquote>
<p>操作性原则，富于弹性，不是绝对的。</p>
</blockquote>
<ul>
<li>切分原则<hanla></hanla>1：有明显分隔符标记的应该切分之。
<ul>
<li>分割标记指标点符号或一个词。如：上、下课-&gt;<hanla></hanla>上<hanla></hanla>/<hanla></hanla>下课</li>
<li>洗了个澡-&gt;<hanla></hanla>洗<hanla></hanla>/<hanla></hanla>了<hanla></hanla>/<hanla></hanla>个<hanla></hanla>/<hanla></hanla>澡</li>
</ul></li>
<li>切分原则<hanla></hanla>2：结构复杂、合并起来过于冗长的词尽量切分。
<ul>
<li><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017184112470.png" srcset="/img/loading.gif" lazyload></li>
</ul></li>
<li>合并原则<hanla></hanla>1：附着性语（词）素与前后词合并为一个单位。
<ul>
<li><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017184231345.png" srcset="/img/loading.gif" lazyload></li>
</ul></li>
<li>合并原则<hanla></hanla>2：使用频率高或共现率高的字串尽量合并。
<ul>
<li><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017184335865.png" srcset="/img/loading.gif" lazyload></li>
</ul></li>
<li>合并原则<hanla></hanla>3：双音节加单音节的偏正式名词合并成一个分词单位。
<ul>
<li><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017184419970.png" srcset="/img/loading.gif" lazyload></li>
</ul></li>
<li>合并原则<hanla></hanla>4：双音节结构的偏正式动词应尽量合并。
<ul>
<li><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017184522338.png" srcset="/img/loading.gif" lazyload></li>
</ul></li>
</ul>
<h4 id="评价指标">评价指标</h4>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017185502290.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017185537174.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017185603969.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="切分方法">切分方法</h3>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017185842433.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="最大匹配法maximum-matching-mm">最大匹配法（Maximum Matching, MM）</h4>
<p>按照切分方向分为：</p>
<ul>
<li>正向最大匹配算法 (Forward MM, FMM)</li>
<li>逆向最大匹配算法 (Backward MM,BMM)</li>
<li>双向最大匹配算法 (Bi-directional MM)</li>
</ul>
<p>基本思路：</p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017190244636.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017190332484.png" srcset="/img/loading.gif" lazyload></p>
<p>FMM<hanla></hanla>算法描述：</p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017190936847.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="基于语言模型的分词方法">基于语言模型的分词方法</h4>
<p>基本思路：</p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017192711856.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="由字构词的分词方法character-based-tagging">由字构词的分词方法<hanla></hanla>(character-based tagging)</h4>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017192851838.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="生成式方法与区分式方法的结合">生成式方法与区分式方法的结合</h4>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017192939164.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="基于神经网络的分词方法">基于神经网络的分词方法</h4>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017193015881.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017193057388.png" srcset="/img/loading.gif" lazyload></p>
<p>可用的分词工具：</p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017193153363.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="命名实体识别">命名实体识别</h3>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017193318623.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017193348424.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017193410119.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017193454480.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251017193523297.png" srcset="/img/loading.gif" lazyload></p>
<p><strong>领域差异和生词识别是分词和 NER 面临的最大挑战</strong></p>
<h3 id="子词压缩"><strong>子词压缩</strong></h3>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251020180753166.png" srcset="/img/loading.gif" lazyload></p>
<p>基本思路：</p>
<ul>
<li>对于英语等屈折语文本，可直接用<strong>双字节编码算法<hanla></hanla>(Pair Encoding, BPE)</strong> 算法进行 字符压缩。</li>
<li>对于汉语文本，如果有很好的分词工具，先对文本进行词语切分，在切分结果的基础上利用<hanla></hanla>BPE<hanla></hanla>算法进行单字压缩，合并那些最大次数的相邻汉字或字符。</li>
</ul>
<p>BPE<hanla></hanla>算法：</p>
<p>①对邻近的两个字符<hanla></hanla>(汉字)<hanla></hanla>合并，统计被合并的两个邻近字符<hanla></hanla>(汉字)<hanla></hanla>在整个文本中出现的次数<span class="math inline"><em>α</em></span>；</p>
<p>②将<span class="math inline"><em>α</em></span>最大的两个邻近字符<hanla></hanla>(汉字)<hanla></hanla>用原文本中不存在的符号替换<hanla></hanla>(压缩)，重复进行上面的操纵。直到没有被合并的字符<hanla></hanla>(汉字)<hanla></hanla>为止，或者达到限定合并的次数。</p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251020181153264.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="词性标注">词性标注</h3>
<p><strong>词性或称词类<hanla></hanla>(Part-of-Speech, POS)</strong><hanla></hanla>是词汇最重要的特性，是语言中词的语法分类，具有相同句法功能、能够出现在同样的组合位置中的词，聚合在一起所形成的范畴。<strong>词类连接词汇到句法的桥梁。</strong></p>
<p>如在汉语中，词类分为两大类：实词<hanla></hanla>(content words)<hanla></hanla>和虚词<hanla></hanla>(functional words)，实词包括体词、谓词，体词又包括名词、代词等，谓词包括动词、形容词等。</p>
<p><strong>词性标注的任务是让系统自动对词汇标注词性标记。</strong></p>
<p>标注集的确定原则：不同语言中，词性划分基本上已经约定俗成。 自然语言处理中对词性标记要求相对细致。</p>
<p><strong>一般原则：</strong></p>
<ul>
<li>标准性 : 普遍使用和认可的分类标准和符号集；</li>
<li>兼容性 : 与已有资源标记尽量一致，或可转换；</li>
<li>可扩展性 ：扩充或修改。</li>
</ul>
<p><strong>标注方法：</strong></p>
<ul>
<li>基于规则<hanla></hanla>/<hanla></hanla>有限状态机的词性标注方法</li>
<li>基于统计模型的词性标注方法
<ul>
<li>HMM：分词与词性标注一体化方法</li>
<li>CRFs：序列标注方法</li>
</ul></li>
<li>规则和统计方法相结合的词性标注方法</li>
</ul>
<p><strong>性能评价指标：准确率</strong></p>
<h2 id="句法分析">句法分析</h2>
<h3 id="短语结构分析">短语结构分析</h3>
<p>短语结构分析<hanla></hanla>(phrase structure parsing)<hanla></hanla>又称成份结构分析<hanla></hanla>(constituent structure parsing)，或简称句法分析<hanla></hanla>(syntactic parsing)，其任务是识别句子的结构关系。</p>
<p>例如，给定如下句子：<strong>他还提出一系列具体措施的政策要点。</strong></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251117104749904.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251117104647237.png" srcset="/img/loading.gif" lazyload></p>
<p>有时候，并不需要分析整个句子的完整结构，而只需要分析句子中的某些短语，如<hanla></hanla>“基本名词短语<hanla></hanla>(baseNP)”：</p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251117104905023.png" srcset="/img/loading.gif" lazyload></p>
<p>如果只分析句子中某种类型的短语结构，这种分析过程称为<strong>局部句法分析<hanla></hanla>(partial parsing)</strong>。</p>
<p>设置句法分析器的目标：实现高准确率、高鲁棒性<hanla></hanla>(robustness)、快速的句子结构自动分析过程。</p>
<p>基本方法：</p>
<ul>
<li>基于<hanla></hanla>CFG<hanla></hanla>规则的分析方法
<ul>
<li>线图分析法（chart parsing）</li>
<li>CYK<hanla></hanla>分析算法</li>
<li>Earley（厄尔利）算法</li>
<li>LR<hanla></hanla>算法<hanla></hanla>/Tomita<hanla></hanla>算法</li>
</ul></li>
<li>基于<hanla></hanla>PCFG<hanla></hanla>的分析方法</li>
<li>基于神经网络的分析方法</li>
</ul>
<h4 id="coke-younger-kasami-cyk-分析算法">Coke-Younger-Kasami (CYK) 分析算法</h4>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251117105308002.png" srcset="/img/loading.gif" lazyload></p>
<p>算法描述：</p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251117105514365.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251117105602252.png" srcset="/img/loading.gif" lazyload></p>
<p>例子：</p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251117110316968.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251117110348902.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="概率上下文无关文法pcfgscfg">概率上下文无关文法<hanla></hanla>(PCFG/SCFG)</h4>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251117110517284.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251117110609954.png" srcset="/img/loading.gif" lazyload></p>
<p>给定句子：<strong>Astronomers saw stars with ears.</strong></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251117111047702.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251117111101594.png" srcset="/img/loading.gif" lazyload></p>
<p>基于<hanla></hanla>PCFG<hanla></hanla>的分析方法评价：</p>
<ul>
<li>优点：
<ul>
<li>可利用概率进行子树剪枝，减少分析过程的搜索空间，加快分析效率</li>
<li>可以定量地比较两个句法分析器的性能</li>
</ul></li>
<li>弱点：分析树的概率计算条件比较苛刻，甚至不够合理</li>
</ul>
<p>短语结构分析结果评价：</p>
<ul>
<li><p><strong>精度（precision）</strong>：句法分析结果中正确的短语个数所占的比例，即分析结果中与标准分析树（答案）中的短语相匹配的个数占分析结果中所有短语个数的比例， 即：</p>
<ul>
<li><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251117111720548.png" srcset="/img/loading.gif" lazyload></li>
</ul></li>
<li><p><strong>召回率 (recall)</strong>：句法分析结果中正确的短语个数占标准分析树中全部短语个数的比例，即：</p>
<ul>
<li><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251117111745305.png" srcset="/img/loading.gif" lazyload></li>
</ul></li>
<li><p><strong>F-measure</strong>：</p></li>
<li><p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251117111807877.png" srcset="/img/loading.gif" lazyload></p></li>
<li><p>一般地，<span class="math inline"><em>β</em> = 1</span>，称作<hanla></hanla><span class="math inline"><em>F</em>1</span><hanla></hanla>测度</p></li>
<li><p><strong>交叉括号数 (crossing brackets)</strong>：一棵分析树中与其他分析树中边界相交叉的成分个 数的平均值。</p></li>
</ul>
<p>​ 分析树中除了词性标注符号以外的其他非终结符节点采用如下标记格式：XP (起始位置：终止位置)。其中，XP<hanla></hanla>为短语名称；(起始位置：终止位置)<hanla></hanla>为该节点的跨越范围，起始位置指该节点所包含的子节点的起始位置，终止位置为该节点所包含的子节点的终止位置。在计算<hanla></hanla>PARSEVAL<hanla></hanla>指标时，通常需要计算分析结果与标准分析树之间括号匹配的数目或括号交叉的数目。</p>
<p><img src="https://blogwzx.oss-cn-beijing.aliyuncs.com/image-20251117112408276.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="依存关系分析">依存关系分析</h3>
<h1 id="第6章-文本表示">第<hanla></hanla>6<hanla></hanla>章 文本表示</h1>
<h2 id="背景">背景</h2>
<h2 id="向量空间模型">向量空间模型</h2>
<h2 id="表示学习模型">表示学习模型</h2>

                
              </div>
            
            <hr>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E5%AD%A6%E4%B9%A0/" class="category-chain-item">学习</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/NLP/" class="print-no-link">#NLP</a>
      
        <a href="/tags/LLM/" class="print-no-link">#LLM</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div><hanla></hanla>自然语言处理与大模型<hanla></hanla></div>
      <div>https://striver98.github.io/2025/09/22/<hanla></hanla>自然语言处理与大模型<hanla></hanla>/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div><hanla></hanla>作者<hanla></hanla></div>
          <div>Wang Zhixuan</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div><hanla></hanla>发布于<hanla></hanla></div>
          <div>2025<hanla></hanla>年<hanla></hanla>9<hanla></hanla>月<hanla></hanla>22<hanla></hanla>日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议<hanla></hanla></div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/09/24/Word2Vec%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/" title="Word2Vec知识总结">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Word2Vec<hanla></hanla>知识总结</span>
                        <span class="visible-mobile">上一篇<hanla></hanla></span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/08/11/Text-image%20Synthesis/" title="Text-image Synthesis">
                        <span class="hidden-mobile">Text-image Synthesis</span>
                        <span class="visible-mobile"><hanla></hanla>下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索<hanla></hanla></h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">×</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input"><hanla></hanla>关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a>
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    

  

</div>

  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script>
  <link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css">

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js"></script>
<script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script>
<script src="/js/events.js"></script>
<script src="/js/plugins.js"></script>





  
    <script src="/js/img-lazyload.js"></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script defer="" src="/js/leancloud.js"></script>

  <script src="/js/local-search.js"></script>

  <script defer="" src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script src="/js/boot.js"></script>


  

  <noscript>
    <div class="noscript-warning"><hanla></hanla>博客在允许 JavaScript 运行的环境下浏览效果更佳<hanla></hanla></div>
  </noscript>


</body></html>